## SIMD指令集

-  **SIMD**，即Single Instruction, Multiple Data，**一条指令操作多个数据**．是**CPU基本指令集的扩展** 

-  主要用于提供fine grain parallelism，即**小碎数据的并行操作** 
  -  比如说图像处理，图像的数据常用的数据类型是RGB565, RGBA8888, YUV422等格式，这些格式的数据特点是**一个像素点的一个分量总是用小于等于８bit的数据表示的** 
  -  如果使用传统的处理器做计算，虽然处理器的寄存器是32位或是64位的 ，处理这些数据确只能用于他们的低８位  似乎有点浪费．如果**把64位寄存器拆成８个８位寄存器就能同时完成８个操作，计算效率提升了８倍**．SIMD指令的初衷就是这样的，只不过后来慢慢cover的功能越来越多． 
-  Intel的初代SIMD指令集是MMX，Multi-Media Extension, 即多媒体扩展，**因为它的首要目标是为了支持MPEG视频解码**．MMX将64位寄存当作2X32或8X8来用，只能处理整形计算．**这样的64位寄存器有８组，分别命名为MM0~MM7**．这些寄存器不是为MMX单独设置的，而是借用的FPU的寄存器，也就是说MMX指令执行的时候，FPU就没有办法工作
-  后来Intel进一步实现了**SSE, SSE2~SSE4指令集**，给了他们单独的寄存器，之后MMX就被停掉了． 
- ． 

## 发展历史 

 https://www.cnblogs.com/bonelee/p/9920610.html 

 SSE, SSE2一直到SSE4，AVX都是一代一代发展过来的，基本上是在原来的基础上增加一些功能，这个增加的过程在网上找到了一张图可以很好的解释． 

 SSE首先就是有了属于自己的8个128位长的寄存器，即32x4，可以支持４个单精度浮点数同时计算,这８个寄存器称为XMM0~XMM7, SSE指令要求数据是16byte对齐的．SSE2则进一步支持双精度浮点数，由于寄存器长度没有变长，所以只能支持２个双精度浮点计算或是４个单精度浮点计算．另外，它在这组寄存器上实现了整型计算，从而代替了MMX．SSE3支持一些更加复杂的算术计算．**SSE4增加了更多指令，并且在数据搬移上下了一番工夫，支持不对齐的数据搬移，增加了super shuffle引擎．** 

## AVX指令

**百度百科**：

 AVX指令集是Sandy Bridge和Larrabee架构下的新指令集。AVX是在之前的128bit扩展到和256bit的SIMD(Single Instruction, Multiple Data)。而Sandy Bridge的SIMD演算单元扩展到256bits的同时数据传输也获得了提升，所以从理论上看CPU内核[浮点运算](http://link.zhihu.com/?target=https%3A//baike.baidu.com/item/%E6%B5%AE%E7%82%B9%E8%BF%90%E7%AE%97)性能提升到了2倍。
Intel AVX指令集，在SIMD计算性能增强的同时也沿用了的MMX/[SSE指令集](http://link.zhihu.com/?target=https%3A//baike.baidu.com/item/SSE%E6%8C%87%E4%BB%A4%E9%9B%86)。不过和MMX/SSE的不同点在于增强的AVX指令，从指令的格式上就发生了很大的变化。x86(IA-32/Intel 64)架构的基础上增加了prefix(Prefix)，所以实现了新的命令，也使更加复杂的指令得以实现，从而提升了x86 CPU的性能。 





 说起AVX来，还有一个有意思的故事。SSE及其后面的进化过程中一直是增加其后面的数字，即SSE2, SSE3, SSE4，按理说下一次进化应该称为SSE5。实际上SSE5是存在的，只不过仅存在于AMD的处理器里。前几代SSE处理器都是Intel先出，然后AMD跟随，然而到SSE4之后，突然**AMD先出了SSE5**，抢了Intel的先。Intel不能忍，于是SSE5就没了。 



 2007年8月，AMD抢先宣布了SSE5指令集（之前从SSE到SSE4均为Intel制定），当时表示该指令集将于2009年推出的Bulldozer处理器中采用。但Intel随即表示，不会支持SSE5。转而在2008年3月，Intel宣布了Sandy Bridge微架构（Intel Tick-Tock策略：45nm Nehalem - 32nm Westmere - 32nm Sandy Bridge），**其中将引入全新的AVX指令集。4月份，Intel公布了AVX指令集规范**，随后开始不断进行更新 



 AVX（Advanced Vector Extensions，高级矢量扩展）**指令集借鉴了一些AMD SSE5的设计思路，进行扩展和加强，形成一套新一代的完整SIMD指令集规范。** 

 https://www.expreview.com/13236.html 

英特尔AVX指令集主要在以下几个方面得到扩充和加强：

- ·支持**256位矢量计算，浮点性能最大提升2倍**
  -  自1999年SSE将矢量处理能力从64位提升到128位后，SSE系列指令都只能使用128位XMM寄存器，这次AVX将所有16个128位XMM寄存器扩充为256位的YMM寄存器，**从而支持256位的矢量计算** 
  -  这意味着可以**同时处理8个32bit的浮点**或是一个256bit的浮点，在写程序时可以忽略SSE 128bit的限制，直接写入一个可以进行多组操作，能够充分利用256bit数据位宽的代码，**理想状态下，浮点性能最高能达到前代的2倍水平** 
  -  当然有时并不是能完全能利用这256位，在大多数情况下，这些寄存器的高128位是设为0或者是“left unchanged”，同时所有的SSE/SSE2/SSE3/SSSE3/SSE4**指令是被AVX全面兼容的**（AVX不兼容MMX），因此实际操作的是YMM寄存器的低128位，在这一点上与原来的SSE系列指令集无异。 
  -  为了满足指令集带来的改进，Load载入单元也要适应一次载入256Bit的能力，所以增加了一组载入单元完成载入操作，并不是单纯的将带宽扩展一倍。这样可以在**一个时钟周期内实现256位的乘、加和Shuffle**运算。 
  -  AVX还**引入了很多新的浮点运算指令**，**浮点运算能力加强，不光提升了3D游戏，还可以更有效的支持如复杂的flash显示，更快的SVG（可伸缩矢量图形）支持，更好的HTML5效果等等**，相比用GPU计算来讲功耗更小，体积更小，成本也小，**对GPU计算是个不大不小的冲击**。 

- ·增强的数据重排，**更有效存取数据**
  
- 
  
- ·支持3操作数和4操作数，在**矢量和标量代码中能更好使用寄存器**

  -  通常一条计算机指令包括有操作码和操作数（operands），操作码决定要完成的操作，操作数指参加运算的数据及其所在的单元地址。比如movaps xmm1, xmm0就是一个双操作数，SSE指令movaps为操作码，其功能是将xmm0寄存器的内容复制给xmm1。 

  -  *新的3操作数和4操作数格式* 

    -  AVX指令集改进和加强了原有的在3个操作数指令的编码和语法，使之更灵活。比如要实现 xmm10 = xmm9 + xmm1 的功能，以前需要两个指令执行： 

    - ```
      　movapps xmm10, xmm9　　　　　　 将xmm9寄存器数据copy到xmm10
        　　　　addpd xmm10, xmm1　　　　　　　　将xmm1和xmm10寄存器数据相加，并存放到xmm10
      ```

      

    -  应用AVX指令集新的3操作数方式，可以直接由一条指令就能完成： 

      - ```
        vaddpd xmm10, xmm9, xmm1
        ```

         **显然AVX三操作数能带来更少的寄存器复制，并且代码也更精简。** 

    -  4操作数虽然是AMD在SSE5中首先提出的 , 但英特尔的AVX也能支持这一方式，其最终收益是对AVX 128和AVX 256使用非破坏性语法，减少寄存器间的拷贝，精简代码，增加load/op fusion的机会 

    - ```
      　movaps xmm0, xmm4
        　　　　movaps xmm1, xmm2
        　　　　blendvps xmm1, m128
      ```

    - 比如上面的三条指令，利用4操作数，可以不需要使用隐含的xmm0，直接由下面一条指令完成：

      ```
      　vblendvps xmm1, xmm2, m128, xmm4
      ```

      

    

  

- 

- ·支持灵活的**不对齐内存地址访问**

  -  CPU在工作时只能按照内部数据位宽长度（比如说32bit）的整倍数为边界进行内存操作，即只能从地址0、32、64、96...处进行存取，而不能从27、58、83等非边界地址处进行。如果一定要取这些非边界地址处的内容，则必须用若干个操作将其凑出来，因而大大影响存取效率 

  -  一个结构体的设计长度却并不一定是32的倍数，例如一个六个字符的结构其长度为48位，如果多个这样的结构在内存中顺着摆放，则许多结构的起始地址将不在边界处**，因此编译程序总是会将每个结构的尾部都加入一些必要的空白，将其凑成32的整数倍，这就是边界对齐的基本道理**。 

  - 　传统的指令中，**当访问不对齐内存（unaligned memory access）时，需要相当大的访问周期，甚至会有惩罚性延时，极大地降低速度**。

    　　而在AVX指令集中，以VEX前缀编码的算术指令和内存访问指令在访问内存时更灵活，既可访问对齐的内存地址，也可访问未对齐的数据。当然访问未对齐数据，多少都会有损失，**但相对传统的指令来说，所承受的惩罚要小得多**。

- ·支持灵活的**扩展性强的VEX编码方式，可减少代码**

**由于AMD的SSE5和AVX指令集功能类似，**并且AVX包含更多的优秀特性，虽然SSE5是要早于AVX宣布的，但在去年AMD还是决定支持AVX，**避免让开发者徒增开发难度**。**同时AMD改写SSE5**，重定义为XOP、CVT16和FMA4指令集。AMD有关人员甚至暗示由于受到了AVX指令集影响，Bulldozer的计划从2010年延迟到了2011年。

　　AVX作为Sandy Bridge处理器最重要的改进，在几天后将闪亮登场，除硬件支持外，软件上的支持也是必不可少的，所幸的是Windows 7 SP1已经开始支持英特尔AVX指令集了。















## 查看系统支持能力

由于SIMD指令有多个版本，每个版本支持的指令集不同。**所以如果你的软件要支持更多的CPU，就要在使用SIMD指令之前知道当前指令运行所在的CPU是否支持这条指令。**

x86/x86_64 提供了**CPUID指令**，**可以通过这个指令查询当前CPU指令支持SSE指令集情况。**

CPUID指令可以用来查询CPU的好多东西，Intel有一个超过100页的文档，专门介绍cpuid这条指令。这里我们仅介绍一下SSE相关的内容，后面如有机会也可以专门介绍一下这条指令。

首先， CPUID指令是从80486开始才有，之前的CPU没有这条指令，当然这个问题大家大可不必担心，因为你能用到486之前的处理器的机会机乎没有，除非你用模拟器去专门模拟这个处理器。

在EFLAGS中的bit 21可以识别CPU是否支持CPUID指令，如下图：